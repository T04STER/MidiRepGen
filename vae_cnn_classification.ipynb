{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f46c3d3c",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf4db3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10854 MIDI files in the dataset.\n",
      "Found 2569 unique composers in the dataset.\n",
      "Ratio of MIDI files to composers: 4.22\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "midi_files = [f for f in os.listdir('data/midi_dataset/midis') if os.path.isfile(os.path.join('data/midi_dataset/midis', f))]\n",
    "print(f\"Found {len(midi_files)} MIDI files in the dataset.\")\n",
    "\n",
    "composers = set([ f.split(',')[0] for f in midi_files if f.endswith('.mid') ])\n",
    "print(f\"Found {len(composers)} unique composers in the dataset.\")\n",
    "print(f\"Ratio of MIDI files to composers: {len(midi_files) / len(composers):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c252c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 composers by file count:\n",
      "Scarlatti: 279\n",
      "Bach: 246\n",
      "Liszt: 197\n",
      "Schubert: 131\n",
      "Chopin: 102\n",
      "Mozart: 90\n",
      "Beethoven: 82\n",
      "Czerny: 80\n",
      "Handel: 78\n",
      "Carbajo: 77\n",
      "\n",
      "Last 10 composers by file count:\n",
      "Żołnowski: 1\n",
      "Łodwigowski: 1\n",
      "Zwyssig: 1\n",
      "Zweig: 1\n",
      "Zwart: 1\n",
      "Zurluth: 1\n",
      "Zopff: 1\n",
      "Zoeller: 1\n",
      "Ziring: 1\n",
      "Zintl: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count files per composer\n",
    "composer_counts = Counter([f.split(',')[0] for f in midi_files if f.endswith('.mid')])\n",
    "\n",
    "# Top 10 composers\n",
    "top_10 = composer_counts.most_common(10)\n",
    "print(\"Top 10 composers by file count:\")\n",
    "for composer, count in top_10:\n",
    "    print(f\"{composer}: {count}\")\n",
    "\n",
    "# Last 10 composers (least files)\n",
    "last_10 = composer_counts.most_common()[:-11:-1]\n",
    "print(\"\\nLast 10 composers by file count:\")\n",
    "for composer, count in last_10:\n",
    "    print(f\"{composer}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a99e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of composers with more than 50 files: 42\n"
     ]
    }
   ],
   "source": [
    "num_composers_over = sum(1 for count in composer_counts.values() if count > 20)\n",
    "print(f\"Number of composers with more than 50 files: {num_composers_over}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6a05489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files for top composers: 1949\n"
     ]
    }
   ],
   "source": [
    "top = composer_counts.most_common(20)\n",
    "# Sum the file counts for these composers\n",
    "top_sum = sum(count for _, count in top)\n",
    "print(f\"Total number of files for top composers: {top_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3129e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files for top 20 composers: 1949\n"
     ]
    }
   ],
   "source": [
    "top_composers_files = [f for f in midi_files if f.split(',')[0] in dict(top).keys()]\n",
    "print(f\"Number of files for top 20 composers: {len(top_composers_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fb61100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "# Split datasets\n",
    "# Group files by composer\n",
    "composer_to_files = defaultdict(list)\n",
    "for f in top_composers_files:\n",
    "    composer_name = f.split(',')[0]\n",
    "    composer_to_files[composer_name].append(f)\n",
    "\n",
    "train_files = []\n",
    "test_files = []\n",
    "\n",
    "for files in composer_to_files.values():\n",
    "    train, test = train_test_split(files, test_size=0.2, random_state=42)\n",
    "    train_files.extend(train)\n",
    "    test_files.extend(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fee1253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alkan, Charles-Valentin, 3 Improvisations dans le Style brillant, Op.12, ORT-ei5_X8w.mid', 'Alkan, Charles-Valentin, Les mois, Op.74, Pzth1MU5JFY.mid', 'Alkan, Charles-Valentin, 2e verset du 41e Psaume, S7-WAxfY3VM.mid', 'Alkan, Charles-Valentin, Pour Monsieur Gurkhaus, L2ajYW7C75s.mid', 'Alkan, Charles-Valentin, 2 Petites pièces, Op.60, jcvaJLXSC0c.mid']\n",
      "['Alkan, Charles-Valentin, Etude, WoO, c297e_yjlAQ.mid', 'Alkan, Charles-Valentin, Réconciliation, Op.42, MGwcbrYFsiU.mid', \"Alkan, Charles-Valentin, Variations sur 'Ah ! segnata é la mia morte', Op.16 No.4, -sSHCvni-NU.mid\", 'Alkan, Charles-Valentin, 3 Petites fantaisies, Op.41, CptNa_Pa7b0.mid', 'Alkan, Charles-Valentin, Salut, Cendre de Pauvre, Op.45, HxD_ReBdT-M.mid']\n"
     ]
    }
   ],
   "source": [
    "print(train_files[:5])\n",
    "print(test_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "032f0909",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/midi_dataset/midis'\n",
    "train_files = [os.path.join(data_dir, f) for f in train_files]\n",
    "test_files = [os.path.join(data_dir, f) for f in test_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a6e9ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/midi_dataset/midis\\\\Alkan, Charles-Valentin, 3 Improvisations dans le Style brillant, Op.12, ORT-ei5_X8w.mid', 'data/midi_dataset/midis\\\\Alkan, Charles-Valentin, Les mois, Op.74, Pzth1MU5JFY.mid', 'data/midi_dataset/midis\\\\Alkan, Charles-Valentin, 2e verset du 41e Psaume, S7-WAxfY3VM.mid', 'data/midi_dataset/midis\\\\Alkan, Charles-Valentin, Pour Monsieur Gurkhaus, L2ajYW7C75s.mid', 'data/midi_dataset/midis\\\\Alkan, Charles-Valentin, 2 Petites pièces, Op.60, jcvaJLXSC0c.mid']\n",
      "['data/midi_dataset/midis\\\\Alkan, Charles-Valentin, Etude, WoO, c297e_yjlAQ.mid', 'data/midi_dataset/midis\\\\Alkan, Charles-Valentin, Réconciliation, Op.42, MGwcbrYFsiU.mid', \"data/midi_dataset/midis\\\\Alkan, Charles-Valentin, Variations sur 'Ah ! segnata é la mia morte', Op.16 No.4, -sSHCvni-NU.mid\", 'data/midi_dataset/midis\\\\Alkan, Charles-Valentin, 3 Petites fantaisies, Op.41, CptNa_Pa7b0.mid', 'data/midi_dataset/midis\\\\Alkan, Charles-Valentin, Salut, Cendre de Pauvre, Op.45, HxD_ReBdT-M.mid']\n"
     ]
    }
   ],
   "source": [
    "print(train_files[:5])\n",
    "print(test_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "16db2761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1551 MIDI files in, frame rate set to 64 FPS.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1551/1551 [02:43<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Alkan', 1: 'Bach', 2: 'Beatty', 3: 'Beethoven', 4: 'Carbajo', 5: 'Chopin', 6: 'Czerny', 7: 'Gottschalk', 8: 'Handel', 9: 'Haydn', 10: 'Liszt', 11: 'Mozart', 12: 'Rebikov', 13: 'Scarlatti', 14: 'Schubert', 15: 'Schumann', 16: 'Scott', 17: 'Scriabin', 18: 'Simpson', 19: 'Zhang'}\n",
      "Initialized 73448 MIDI tensors with 20 unique composers.\n",
      "Dataset saved to data/preprocessed_classification_piano_roll.pkl\n"
     ]
    }
   ],
   "source": [
    "from src.dataloader.dataset import PianoRollClassificationDataset\n",
    "import pickle\n",
    "\n",
    "\n",
    "pitch_to_strip = (24, 84)  # Take  only pitches between 24 and 84 C1 to C6 (https://arxiv.org/pdf/1809.07600)\n",
    "\n",
    "train_dataset = PianoRollClassificationDataset(\n",
    "    midi_files=train_files,\n",
    "    frame_per_second=64,\n",
    "    verbose=True,\n",
    "    strip_bounds=True,\n",
    "    pitch_to_strip=pitch_to_strip\n",
    ")\n",
    "\n",
    "out_path = \"data/preprocessed_classification_piano_roll.pkl\"\n",
    "\n",
    "pickle.dump(\n",
    "    train_dataset,\n",
    "    open(out_path, \"wb\"),\n",
    ")\n",
    "print(f\"Dataset saved to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29ed6553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from src import dataloader\n",
    "reload(dataloader.dataset)\n",
    "from src.dataloader.dataset import PianoRollClassificationDataset\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a928380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 398 MIDI files in, frame rate set to 64 FPS.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [00:47<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Alkan', 1: 'Bach', 2: 'Beatty', 3: 'Beethoven', 4: 'Carbajo', 5: 'Chopin', 6: 'Czerny', 7: 'Gottschalk', 8: 'Handel', 9: 'Haydn', 10: 'Liszt', 11: 'Mozart', 12: 'Rebikov', 13: 'Scarlatti', 14: 'Schubert', 15: 'Schumann', 16: 'Scott', 17: 'Scriabin', 18: 'Simpson', 19: 'Zhang'}\n",
      "Initialized 20584 MIDI tensors with 20 unique composers.\n",
      "Dataset saved to data/preprocessed_classification_piano_roll_test.pkl\n"
     ]
    }
   ],
   "source": [
    "test_dataset = PianoRollClassificationDataset(\n",
    "    midi_files=test_files,\n",
    "    frame_per_second=64,\n",
    "    verbose=True,\n",
    "    strip_bounds=True,\n",
    "    pitch_to_strip=pitch_to_strip\n",
    ")\n",
    "\n",
    "out_path = \"data/preprocessed_classification_piano_roll_test.pkl\"\n",
    "\n",
    "pickle.dump(\n",
    "    test_dataset,\n",
    "    open(out_path, \"wb\"),\n",
    ")\n",
    "print(f\"Dataset saved to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09af36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset: PianoRollClassificationDataset = pickle.load(open(\"data/preprocessed_classification_piano_roll.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a222a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset: PianoRollClassificationDataset = pickle.load(open(\"data/preprocessed_classification_piano_roll_test.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a87c8a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Alkan',\n",
       " 1: 'Bach',\n",
       " 2: 'Beatty',\n",
       " 3: 'Beethoven',\n",
       " 4: 'Carbajo',\n",
       " 5: 'Chopin',\n",
       " 6: 'Czerny',\n",
       " 7: 'Gottschalk',\n",
       " 8: 'Handel',\n",
       " 9: 'Haydn',\n",
       " 10: 'Liszt',\n",
       " 11: 'Mozart',\n",
       " 12: 'Rebikov',\n",
       " 13: 'Scarlatti',\n",
       " 14: 'Schubert',\n",
       " 15: 'Schumann',\n",
       " 16: 'Scott',\n",
       " 17: 'Scriabin',\n",
       " 18: 'Simpson',\n",
       " 19: 'Zhang'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.labels_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf0c5abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Alkan',\n",
       " 1: 'Bach',\n",
       " 2: 'Beatty',\n",
       " 3: 'Beethoven',\n",
       " 4: 'Carbajo',\n",
       " 5: 'Chopin',\n",
       " 6: 'Czerny',\n",
       " 7: 'Gottschalk',\n",
       " 8: 'Handel',\n",
       " 9: 'Haydn',\n",
       " 10: 'Liszt',\n",
       " 11: 'Mozart',\n",
       " 12: 'Rebikov',\n",
       " 13: 'Scarlatti',\n",
       " 14: 'Schubert',\n",
       " 15: 'Schumann',\n",
       " 16: 'Scott',\n",
       " 17: 'Scriabin',\n",
       " 18: 'Simpson',\n",
       " 19: 'Zhang'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.labels_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179cd67a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62273403",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35f7ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "midi_dataloader_train = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "24a0409d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.7165, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.7165, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.7165, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]), tensor([ 3, 13,  6,  2,  3,  5,  9, 13, 18,  6,  5,  5, 14, 13, 10, 14, 12,  1,\n",
      "        18, 14, 12,  2,  3,  2,  2, 14,  4,  6, 10, 17, 15, 15,  3, 14, 10,  6,\n",
      "        10,  1,  1,  4,  6, 14, 12,  6,  9, 10, 14, 14,  3, 14, 14,  1,  5,  5,\n",
      "        11, 15, 10,  1,  4,  9, 18, 14,  3,  1])]\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(midi_dataloader_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca0986f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super(PrintLayer, self).__init__()\n",
    "        self.name = name\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"{self.name}: {x.shape}\")\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNNVAE(nn.Module):\n",
    "    def __init__(self, input_shape=(60, 640), latent_dim=256, print_shapes=False):\n",
    "        super(CNNVAE, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape  # (height=pitch, width=time)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.print_shapes = print_shapes\n",
    "        \n",
    "        ### Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=9, stride=1, padding=4),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),  # -> 30x320\n",
    "\n",
    "            PrintLayer(\"Conv1 Output\") if print_shapes else nn.Identity(),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=9, stride=1, padding=4),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),  # -> 15x160\n",
    "\n",
    "            PrintLayer(\"Conv2 Output\") if print_shapes else nn.Identity(),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=9, stride=1, padding=4),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),  # -> 7x80\n",
    "\n",
    "            PrintLayer(\"Conv3 Output\") if print_shapes else nn.Identity(),\n",
    "        )\n",
    "        \n",
    "        # Calculate dimensions before linear layer\n",
    "        self._calculate_fc_dim()\n",
    "        \n",
    "        # Latent space\n",
    "        self.fc_mu = nn.Linear(self.fc_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(self.fc_dim, latent_dim)\n",
    "        self.fc_decode = nn.Linear(latent_dim, self.fc_dim)\n",
    "        \n",
    "        ### Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Upsample(size=(160, 15), mode='nearest'),\n",
    "            nn.Conv2d(128, 64, kernel_size=9, stride=1, padding=4),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            PrintLayer(\"Decoder Upsample 1 Output\") if print_shapes else nn.Identity(),\n",
    "            \n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(64, 32, kernel_size=9, stride=1, padding=4),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            PrintLayer(\"Decoder Upsample 2 Output\") if print_shapes else nn.Identity(),\n",
    "            \n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(32, 1, kernel_size=9, stride=1, padding=4),\n",
    "            nn.Sigmoid(),\n",
    "\n",
    "            PrintLayer(\"Decoder Output\") if print_shapes else nn.Identity(),\n",
    "        )\n",
    "\n",
    "    def _calculate_fc_dim(self):\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 1, *self.input_shape)\n",
    "            dummy_output = self.encoder(dummy_input)\n",
    "            self.fc_dim = dummy_output.numel() // dummy_output.shape[0]\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.fc_decode(z)\n",
    "        z = z.view(z.size(0), 128, 80, 7)\n",
    "        z = self.decoder(z)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c563be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNVAELoss(nn.Module):\n",
    "    def __init__(self, beta=1.0):\n",
    "        super(CNNVAELoss, self).__init__()\n",
    "        self.beta = beta\n",
    "\n",
    "    def mse_loss(self, x, x_recon):\n",
    "        return F.mse_loss(x_recon, x)\n",
    "    \n",
    "    def mae_loss(self, x, x_recon):\n",
    "        return F.l1_loss(x_recon, x)\n",
    "\n",
    "    def min_threshold_loss(self, y_true, y_pred, min_val=1/127, penalty_strength=10.0):\n",
    "        significant_mask = torch.sigmoid((y_true - min_val) * 100)\n",
    "        penalty = torch.exp(-penalty_strength * (y_pred / min_val))\n",
    "        loss = significant_mask * penalty\n",
    "        return loss.mean()\n",
    "\n",
    "    def kl_divergence(self, mu, logvar):\n",
    "        # KL divergence between N(mu, sigma^2) and N(0, 1)\n",
    "        return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1).mean()\n",
    "    \n",
    "    # def binary_penalty_loss(self, x, x_recon):\n",
    "    #     \"\"\"Penalty for model giving 0s where it should be non zero pitch value, or vice versa.\"\"\"\n",
    "    #     binary_x = (x > 0.1).float()\n",
    "    #     binary_x_recon = (x_recon > 0.1).float()\n",
    "    #     penalty = F.binary_cross_entropy(binary_x_recon, binary_x, reduction='none')\n",
    "    #     return penalty.mean()\n",
    "\n",
    "    def forward(self, x, x_recon, mu, logvar):\n",
    "        mse = self.mse_loss(x, x_recon)\n",
    "        penalty = 100 * self.min_threshold_loss(x, x_recon, min_val=0.016, penalty_strength=10.0)\n",
    "        kl = self.kl_divergence(mu, logvar)\n",
    "        total_loss = mse + penalty + self.beta * kl\n",
    "        # return total_loss, mse, penalty, kl\n",
    "        # mae = self.mae_loss(x, x_recon)\n",
    "        # penalty = self.binary_penalty_loss(x, x_recon)\n",
    "        # total_loss = mse + penalty + self.beta * kl\n",
    "        return total_loss, mse, penalty, kl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f956280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e29a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_vae(model, dataloader, epochs=10, lr=1e-3, patience=3, beta=1.0):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = CNNVAELoss(beta=beta)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_mse_loss = 0.0\n",
    "        total_penalty_loss = 0.0\n",
    "        total_kl_loss = 0.0\n",
    "\n",
    "        iter_batch = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\", leave=False)\n",
    "        for batch in iter_batch:\n",
    "            batch = batch.to(device)\n",
    "            batch = batch.unsqueeze(1)  # Add channel dimension\n",
    "            optimizer.zero_grad()\n",
    "            x_recon, mu, logvar = model(batch)\n",
    "            loss, mse_loss, penalty_loss, kl_loss = criterion(batch, x_recon, mu, logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            total_mse_loss += mse_loss.item()\n",
    "            total_penalty_loss += penalty_loss.item()\n",
    "            total_kl_loss += kl_loss.item()\n",
    "            iter_batch.set_postfix(\n",
    "                loss=loss.item(),\n",
    "                mse_loss=mse_loss.item(),\n",
    "                penalty_loss=penalty_loss.item(),\n",
    "                kl_loss=kl_loss.item()\n",
    "            )\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_mse_loss = total_mse_loss / len(dataloader)\n",
    "        avg_penalty_loss = total_penalty_loss / len(dataloader)\n",
    "        avg_kl_loss = total_kl_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, MSE: {avg_mse_loss:.4f}, Penalty: {avg_penalty_loss:.4f}, KL: {avg_kl_loss:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "                break\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"Best model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b3f666",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model = CNNVAE(input_shape=(60, 640), latent_dim=256 * 2).cuda()\n",
    "train_vae(vae_model, midi_dataloader, epochs=10, lr=0.0001, beta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9baf3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vae_model, 'data/vae_cnn_v3.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "midiv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
